1
A Survey of Semantic Segmentation
Martin Thoma
info@martin-thoma.de
Abstract
≈†This survey gives an overview over different
techniques used for pixel-level semantic segmentation.
Metrics and datasets for the evaluation of segmenta-
tion algorithms and traditional approaches for segmen-
tation such as unsupervised methods, Decision Forests
and SVMs are described and pointers to the relevant
papers are given. Recently published approaches with
convolutional neural networks are mentioned and typical
problematic situations for segmentation algorithms are
examined. A taxonomy of segmentation algorithms is
given.
I. I
NTRODUCTION
Semantic segmentation is the task of clustering
parts of images together which belong to the same
object class. This type of algorithm has several use-
cases such as detecting road signs [
MBLAGJ
+
07
],
detecting tumors [
MBVLG02
], detecting medical in-
struments in operations [
WAH97
], colon crypts segmen-
tation [
CRSS14
], land use and land cover classica-
tion [
HDT02
]. In contrast, non-semantic segmentation
only clusters pixels together based on general character-
istics of single objects. Hence the task of non-semantic
segmentation is not well-dened, as many different
segmentations might be acceptable.
Several applications of segmentation in medicine are
listed in [PXP00].
Object detection, in comparison to semantic seg-
mentation, has to distinguish different instances of the
same object. While having a semantic segmentation
is certainly a big advantage when trying to get object
instances, there are a couple of problems: neighboring
pixels of the same class might belong to different object
instances and regions which are not connected my
belong to the same object instance. For example, a
tree in front of a car which visually divides the car into
two parts.
Thispaperisorganizedasfollows:Itbeginsbygiving
a taxonomy of segmentation algorithms in Section II.
A summary of quality measures and datasets which are
used for semantic segmentation follows in Section III.
A summary of traditional segmentation algorithms and
their characteristics follows in Section V, as well as a
brief, non-exhaustive summary of recently published
semantic segmentation algorithms which are based on
neural networks in Section VI. Finally, Section VII
informs the reader about typical problematic cases for
segmentation algorithms.
II. T
AXONOMY OF
S
EGMENTATION
A
LGORITHMS
The computer vision community has published a
wide range of segmentation algorithms so far. Those
algorithms can be grouped by the kind of data they
operate on and the kind of segmentation they are able
to produce.
The following subsections will give four different
criteria by which segmentation algorithms can be
classied.
This survey describes xed-class (see Section
II-A
),
single-class afliation (see Section
II-B
) algorithms
which work on grayscale or colored single pixel images
(see Section
II-C
) in a completely automated, passive
fashion (see Section II-D).
A. Allowed classes
Semantic segmentation is a classication task. As
such, the classes on which the algorithm is trained is a
central design decision.
Most algorithms work with a xed set of classes;
some even only work on binary classes like
fore-
ground vs background
[
RM07
], [
CS10
] or
street vs
no street
[BKTT15].
However, there are also unsupervised segmentation
algorithms which do not distinguish classes at all (see
Section
V-B
) as well as segmentation algorithms which
are able to recognize when they don't know a class.
For example, in [
GRC
+
08
] a
void class
was added
for classes which were not in the training set. Such
a void class was also used in the MSRCv2 dataset
(see Section
III-B
2) to make it possible to make more
coarse segmentations and thus having to spend less
time annotating the image.
B. Class afliation of pixels
Humans do an incredible job when looking at the
world. For example, when we see a glass of water
standing on a table we can automatically say that there
is the glass and behind it the table, even if we only had a
single image and were not allowed to move. This means
we simultaneously two labels to the coordinates of the
glass: Glass and table. Although there is much more
work being done on
single class afliation
segmenta-
tion algorithms, there is a publication about
multiple
class afliation
segmentation [
LRAL08
]. Similarly,
recent publications in pixel-level object segmentation
used layered models [YHRF12].
arXiv:1602.06541v2  [cs.CV]  11 May 2016
2
C. Input Data
The available data which can be used for the
inference of a segmentation varies by application.

Grayscale vs colored
: Grayscale images are
commonly used in medical imaging such as
magnetic resonance (MR) imaging or ultrasonog-
raphy whereas colored photographs are obviously
widespread.

Excluding or including depth data
: RGB-D,
sometimes also called range [
HJBJ
+
96
] is avail-
able in robotics, autonomous cars and recently
also in consumer electronics such as Microsoft
Kinect [Zha12].

Single image vs stereo images vs co-
segmentation
: Single image segmentation is the
most wide-spread kind of segmentation, but using
stereo images was already tried in [
BVZ01
]. It can
be seen as a more natural way of segmentation as
most mammals have two eyes. It can also be seen
as being related to having depth data.
Co-segmentation as in [
RMBK06
], [
CXGS12
] is
the problem of nding a consistent segmentation
for multiple images. This problem can be seen
in two ways: One the one hand, it can be seen
as the problem of nding common objects in at
least two images. On the other hand, every image
after the rst can be used as an additional source
of information to nd a meaningful segmentation.
This idea can be extended to time series such as
videos.

2D vs 3D
: Segmenting images is a 2D segmenta-
tion task where the smallest unit is called a
pixel
.
In 3D data, such as volumetric X-ray CT images
as they were used in [
HHR01
], the smallest unit
is called a voxel.
D. Operation state
The operation state of the classifying machine can
eitherbe
active
asin[
SUM
+
11
],[
SSA12
]whererobots
can move objects to nd a segmentation or
passive
,
where the received image cannot be inuenced. Among
the passive algorithms, some segment in a completely
automatic
fashion, others work in an
interactive
mode.
One example would be a system where the user clicks
on the background or marks a coarse segmentation and
the algorithm nds a ne-grained segmentation. [
BJ00
],
[
RKB04
], [
PS07
] describe systems which work in an
interactive mode.
(a) Example Scene
(b)
Visualization of a found seg-
mentation
Figure 1:
An example of a scene and a possible visu-
alization of a found segmentation.
III. E
VALUATION AND
D
ATASETS
A. Quality measures for evaluation
A performance measure is a crucial part of any
machine learning system. As users of a semantic
segmentation system expect correct results, the accuracy
is the most commonly used performance measure, but
there are other measures of quality which matter when
segmentation algorithms are compared. This section
gives an overview of those quality measures.
1) Accuracy:
Showingthecorrectnessofthesegmen-
tation hypotheses is done in most publications about
semantic segmentation. However, there are a couple
of different ways how this accuracy can be displayed.
One way to give readers a rst qualitative impression
of the obtained segmentations is by showing examples
such as Figure 1.
However, this can only support the explanation of
particular problems or showcase special situation. For
meaningfulinformationabouttheoverallaccuracy,there
are a couple of metrics how accuracy can be dened.
For this section, let
k
2
N
be the number of classes,
n
ij
2
N
0
with
i;j
2
1
;:::;k
be the number of pixels
which belong to class
i
and were labeled as class
j
.
(
n
ij
)
is called a
confusion matrix
. Let
t
i
=
P
k
j
=1
n
ij
be the total number of pixels of class
i
.
One way to compare segmentation algorithms is by
the pixel-wise accuracy of the predicted segmentation
as done in many publications [
SWRC06
], [
CP08
],
[
LSD14
]. This is also called per-pixel rate and de-
ned as
P
k
i
=1
n
ii
P
k
i
=1
t
i
. Taking the pixel-wise classication
accuracy has two major drawbacks:
P1
Tasks like segmenting images for autonomous cars
have large regions which have one class. This
makes achieving classication accuracies of more
than
30
%
with a priori knowledge only possible.
For example, a system might learn that a certain
position of the image is most of the time Ô¨ÅskyÔ¨Ç
while another position is most of the time Ô¨ÅroadÔ¨Ç.
3
P2
The manually labeled images could have a more
coarse labeling. For example, a human classier
could have labeled a region as Ô¨ÅcarÔ¨Ç and the
algorithm could have split that region into the
general Ô¨ÅcarÔ¨Ç and the more specic Ô¨Åwheel of a
carÔ¨Ç
Three accuracy metrics which do not suffer from
problem P1 are used in [LSD14]:

mean accuracy
:
1
k

P
k
i
=1
n
ii
t
i
2
[0
;
1]

mean intersection over union
:
1
k

P
k
i
=1
n
ii
t
i

n
ii
+
P
k
j
=1
n
ji
2
[0
;
1]

frequency weighted intersection over union
:
(
P
k
i
=1
t
i
)

1
P
k
i
=1
t
i

n
ii
t
i

n
ii
+
P
k
j
=1
n
ji
2
[0
;
1]
Another problem might be pixels which cannot be
assigned to one of the known classes. For this reason,
[
SWRC06
] makes use of a void class. This class gets
completely ignored for all quality measures. Hence the
total number of pixels is assumed to be
width

height

number of void pixels.
One way to deal with problem P1 and problem P2
is giving the confusion matrix as done in [
SWRC06
].
However, this approach is not feasible if many classes
are given.
The
F
-measure is useful for binary classica-
tion task such as the KITTI road segmentation
benchmark [
FKG13
] or crypt segmentation as done
by [
CRSS14
]. It is calculated as Ô¨Åthe harmonic mean
of the precision and recallÔ¨Ç [PH05]:
F

= (1+

)
2
tp
(1+

2
)

tp
+

2

fn
+
fp
where

= 1
is chosen in most cases and
tp
means
true positive
,
fn
means
false negative
and
fp
means
false positive
.
Finally, it should be noted that a lot of other measures
for the accuracy of segmentations were proposed for
non-semantic segmentation. One of those accuracy
measures is
Normalized Probabilistic Rand
(NPR)
index which was introduced in [
UPH05
] and eval-
uated in [
CSI
+
09
] on dermoscopy images. Other
non-semantic segmentation measures were introduced
in[
MFTM01
],butthereasonforcreatingthemseemsto
betodealwiththeunder-denedtaskdescriptionofnon-
semantic segmentation. These accuracy measures try to
deal with different levels of coarsity of the segmentation.
Thisismuchlessofaprobleminsemanticsegmentation
and thus those measures are not explained here.
2) Speed:
Amaximumupperboundontheexecution
time for the inference on a single image is a hard
requirement for some applications. For example, in the
case of autonomous cars an algorithm which classies
pixel as street or no-street and thus makes a semantic
segmentation, every image needs to be processed within
20
ms [BKTT15]. This time is called
latency
.
Most papers do not give exact values for the time
their application needs. One reason might be that this is
very hardware, implementation and in some cases even
data specic. For example, [
HJBJ
+
96
] notes that their
algorithm needs
10
s
on a Sun SparcStation 20. The
fastest CPU ever produced for this system had
200
MHz
.
Comparing this directly with results which were ob-
tained using an Intel i7-4820K with
3
:
9
GHz
would not
be meaningful.
However, it does still make sense to mention the
execution time as well as the hardware in individual
papers. This gives the interested reader the possibility to
estimate how difcult it might be to adjust the algorithm
to work in the required time-constraints.
Besides the latency, the
throughput
is another
relevant characteristic of algorithms and implementa-
tions for semantic segmentation. For example, for the
automatic description of images in order to enable text
search the throughput is of much higher importance
than latency.
3) Stability:
A reasonable requirement on semantic
segmentation algorithms is the stability of a segmen-
tation over slight changes in the input image. When
the image data is sightly blurred by smoke such as
in Figure 4(c), the segmentation should not change.
Also, two images which show a slight change in
perspective should also only result in slight changes in
the segmentation [PH05].
4) Memory usage:
Peak memory usage matters
when segmentation algorithms are used in devices like
smartphones or cameras, or when the algorithms have
to nish in a given time frame, run on the graphics
processing unit (GPU) and consume so much memory
for single image segmentation that only the latest
graphic cards can be used. However, no publication
were available mentioning the peak memory usage.
B. Datasets
The computer vision community produced a couple
of different datasets which are publicly available. In
the following, only the most widely used ones as well
as three medical databases are described. An overview
over the quantity and the kind of data is given by
Table I.
1) PASCAL VOC:
The PASCAL
1
VOC
2
challenge
was organized eight times with different datasets:
Once every year from 2005 to 2012 [
EVGW
+
b
].
1
p
attern
a
nalysis,
s
tatistical modelling and
c
omput
a
tional
l
earning,
an EU network of excellence
2
V
isual
O
bject
C
lasses
4
Beginning with 2007, a segmentation challenge was
added [EVGW
+
a].
The dataset consists of annotated photographs from
www.icker.com, a photo sharing website. There are
multiple challenges for PASCAL VOC. The 2012
competition had ve challenges of which one is a
segmentation challenge where a single class label was
given for each pixel. The classes are: aeroplane, bicycle,
bird, boat, bottle, bus, car, cat, chair, cow, dining table,
dog, horse, motorbike, person, potted plant, sheep, sofa,
train, tv/monitor.
Although no new competitions will be held, new
algorithms can be evaluated on the 2010, 2011 and
2012 data via http://host.robots.ox.ac.uk:8080/
The PASCAL VOC segmentation challenges use the
segmentation over union
criterion (see Section III-A).
2) MSRCv2:
Microsoft Research has published a
database of 591 photographs with pixel-level annotation
of 21 classes: aeroplane, bike, bird, boat, body, book,
building, car, cat, chair, cow, dog, face, ower, grass,
road, sheep, sign, sky, tree, water. Additionally, there
is a
void
label for pixels which do not belong to
any of the 21 classes or which are close to the
segmentation boundary. This allows a Ô¨Årough and quick
hand-segmentation which does not align exactly with
the object boundariesÔ¨Ç [SWRC06].
3) Medical Databases:
The Warwick-QU Dataset
consists of 165 images with pixel-level annotation of
5 classes: Ô¨Åhealthy, adenomatous, moderately differen-
tiated, moderately-to-poorly differentiated, and poorly
differentiatedÔ¨Ç [
CSM09
]. This dataset is part of the
Gland Segmentation (GlaS) challenge.
The DIARETDB1 [
KKV
+
14
] is a dataset of 89 im-
ages fundus images. Those images show the interior
surface of the eye. Fundus images can be used to detect
diabetic retinopathy. The images have four classes of
coarse annotations: hard and soft exudates, hemorrhages
and red small dots.
20 test and additionally 20 training retinal fun-
dus images are available through the DRIVE data
set [
SAN
+
04
]. The vessels were annotated. Addition-
ally, [AP11] added vascular features.
The Open-CAS Endoscopic Datasets [
MHMK
+
14
]
are 60 images taken from laparoscopic adrenalectomies
and 60 images taken from laparoscopic pancreatic
resections. Those are from 3 surgical procedures each.
Half of the data was annotated by a medical expert for
Ô¨Åmedial instrumentÔ¨Ç and Ô¨Åno medical instrumentÔ¨Ç. All
images were labeled by anonymous untrained workers
to which they refer to as
knowledge workers
(KWs).
One crowd annotation was obtained for each image by
a majority vote on a pixel basis of 10 segmentations
given by 10 different KWs.
Figure 2:
A typical segmentation pipeline gets raw
pixel data, applies preprocessing techniques
like scaling and feature extraction like HOG
features. For training, data augmentation
techniques such as image rotation can be
applied. For every single image, patches of
the image called
windows
are extracted and
those windows are classied. The resulting
semantic segmentation can be rened by
simple morphologic operations or by more
complex approaches such as Markov Random
Fields (MRFs).
IV. S
EGMENTATION
P
IPELINE
Typically, semantic segmentation is done with a
classier which operates on xed-size feature inputs
and a
sliding-window
approach [
DT05
], [
YBCK10
],
[SCZ08]. This means a classier is trained on images
of a xed size. The trained classier is then fed with
rectangular regions of the image which are called
win-
dows
. Although the classier gets an image patch of e.g.
51
px

51
px
of the environment, it might only classify
the center pixel or a subset of the complete window.
This segmentation pipeline is visualized in Figure 2.
This approach was taken by [
BKTT15
] and a major-
ity of the VOC2007 participants [
EVGW
+
a
]. As this
approach has to apply the patch classier
512

512 =
262144
times for images of size
512
px

512
px
, there
are techniques for speeding it up such as applying a
stride and interpolating the results.
Neural networks are able to apply the sliding window
approach in a very efcient way by handling a trained
network as a convolution and applying the convolution
on the complete image.
However, there are alternatives. Namely MRFs and
Conditional Random Fields (CRFs) which take the
information of the complete image and segment it in
an holistic approach.
5
V. T
RADITIONAL
A
PPROACHES
Image segmentation algorithms which use traditional
approaches, hence don't apply neural networks and
make heavy use of domain knowledge, are wide-spread
in the computer vision community. Features which can
be used for segmentation are described in Section
V-A
,
a very brief overview of unsupervised, non-semantic
segmentation is given in Section
V-B
, Random Decision
Forests are described in Section
V-C
, Markov Random
Fields in Section
V-E
and Support Vector Machines
(SVMs) in Section
V-D
. Postprocessing is covered in
Section V-G.
It should be noted that algorithms can use combina-
tion of methods. For example, [
TNL14
] makes use of a
combination of a SVM and a MRF. Also, auto-encoders
can be used to learn features which in turn can be used
by any classier.
A. Features and Preprocessing methods
The choice of features is very important in traditional
approaches. The most commonly used local and global
features are explained in the following as well as feature
dimensionality reduction algorithms.
1) Pixel Color:
Pixel color in different image spaces
(e.g. 3 features for RGB, 3 features for HSV, 1 feature
for the gray-value) are the most widely used features. A
typical image is in the RGB color space, but depending
on the classier and the problem another color space
might result in better segmentations. RGB, YcBcr, HSL,
Lab and YIQ are some examples used by [
CRSS14
].
No single color space has been proven to be superior
to all others in all contexts [
CJSW01
]. However, the
most common choices seem to be RGB and HSI.
Reasons for choosing RGB is simplicity and the support
by programming languages, whereas the choice of
the HSI color space might make it simpler for the
classier to become invariant to illumination. One
reason for choosing CIE-L*a*b* color space is that it
approximates human perception of brightness [
KP92
].
It follows that choosing the L*a*b color space helps
algorithms to detect structures which are seen by
humans. Another way of improving the structure within
an image is histogram equalization, which can be
applied to improve contrast [PAA
+
87], [RM07].
2) Histogram of oriented Gradients:
Histogram of
oriented gradients (HOG) features interpret the image
as a discrete function
I
:
N
2
! f
0
;:::;
255
g
which
maps the position
(
x;y
)
to a color. For each pixel, there
are two gradients: The partial derivative of
x
and
y
.
Now the original image is transformed to two feature
maps of equal size which represents the gradient. These
feature maps are splitted into patches and a histogram of
thedirectionsiscalculatedforeachpatch.HOGfeatures
were proposed in [
DT05
] and are used in [
BMBM10
],
[FGMR10] for segmentation tasks.
3) SIFT:
Scale-invariant feature transform (SIFT)
feature descriptors describe keypoints in an image. The
image patch of the size
16

16
around the keypoint
is taken. This patch is divided in
16
distinct parts of
the size
4

4
. For each of those parts a histogram of
8 orientations is calculated similar as for HOG features.
This results in a 128-dimensional feature vector for
each keypoint.
It should be emphasized that SIFT is a global feature
for a complete image.
SIFT is described in detail in [
Low04
] and are used
in [PTN09].
4) BOV:
Bag-of-visual-words (BOV), also called
bag of keypoints
, is based on vector quantization.
Similar to HOG features, BOV features are histograms
which count the number of occurrences of certain
patterns within a patch of the image. BOV are described
in [
CDF
+
04
] and used in combination with SIFT
feature descriptors in [CP08].
5) Poselets: Poselets
rely on manually added extra
keypoints such as Ô¨Åright shoulderÔ¨Ç, Ô¨Åleft shoulderÔ¨Ç,
Ô¨Åright kneeÔ¨Ç and Ô¨Åleft kneeÔ¨Ç. They were originally
used for human pose estimation. Finding those extra
keypoints is easily possible for well-known image
classes like humans. However, it is difcult for classes
like airplanes, ships, organs or cells where the human
annotators do not know the keypoints. Additionally, the
keypointshavetobechosenforeverysingleclass.There
arestrategiestodealwiththoseproblemslikeviewpoint-
dependent keypoints. Poselets were used in [
BMBM10
]
to detect people and in [
BBMM11
] for general object
detection of the PASCAL VOC dataset.
6) Textons:
A
texton
is the minimal building block
of vision. The computer vision literature does not give a
strict denition for textons, but edge detectors could be
one example. One might argue that deep learning tech-
niques with Convolution Neuronal Networks (CNNs)
learn textons in the rst lters.
An excellent explanation of textons can be found
in [ZGWX05].
7) Dimensionality Reduction:
High-resolution im-
ageshavealotofpixels.Havingoneormorefeatureper
pixel results in well over a million features. This makes
training difcult while the higher resolution might not
contain much more information. A simple approach
to deal with this is downsampling the high-resolution
image to a low-resolution variant. Another way of
doing dimensionality reduction is principal component
analysis (PCA), which is applied by [
COWR11
]. The
idea behind PCA is to nd a hyperplane on which all
6
feature vectors can be projected with a minimal loss
of information. A detailed description of PCA is given
by [Smi02].
One problem of PCA is the fact that it does not
distinguish different classes. This means it can happen
that a perfectly linearly separable set of feature vectors
becomes not separable at all after applying PCA.
There are many other techniques for dimensionality
reduction. An overview and a comparison over some
of them is given by [vdMPvdH09].
B. Unsupervised Segmentation
Unsupervised segmentation algorithms can be used
in supervised segmentation as another source of infor-
mation or to rene a segmentation. While unsupervised
segmentation algorithms can never be semantic, they are
well-studied and deserve at least a very brief overview.
Semantic segmentation algorithms store information
about the classes they were trained to segment while
non-semantic segmentation algorithms try to detect
consistent regions or region boundaries.
1) Clustering Algorithms:
Clustering algorithms can
directly be applied on the pixels, when one gives a
feature vector per pixel. Two clustering algorithms are
k
-means and the mean-shift algorithm.
The
k
-means algorithm is a general-purpose cluster-
ing algorithm which requires the number of clusters to
be given beforehand. Initially, it places the
k
centroids
randomly in the feature space. Then it assigns each
data point to the nearest centroid, moves the centroid
to the center of the cluster and continues the process
until a stopping criterion is reached. A faster variant is
described in [Har75].
k
-means was applied by [
CLP98
] for medical image
segmentation.
Another clustering algorithm is the mean-shift algo-
rithm which was introduced by [
CM02
] for segmen-
tation tasks. The algorithm nds the cluster centers
by initializing centroids at random seed points and
iteratively shifting them to the mean coordinate within
acertainrange.Insteadoftakingahardrangeconstraint,
the mean can also be calculated by using any kernel.
This effectively applies a weight to the coordinates
of the points. The mean shift algorithm nds cluster
centers at positions with a highest local density of
points.
2) Graph Based Image Segmentation:
Graph-based
image segmentation algorithms typically interpret pixels
as vertices and an edge weight is a measure of
dissimilarity such as the difference in color [
FH04
],
[
Fel
]. There are several different candidates for edges.
The 4-neighborhood (north, east, south west) or an 8-
neighborhood (north, north-east, east, south-east, south,
south-west, west, north-west) are plausible choices.
One way to cut the edges is by building a minimum
spanning tree and removing edges above a threshold.
This threshold can either be constant, adapted to the
graph or adjusted by the user. After the edge-cutting
step, the connected components are the segments.
A graph-based method which ranked 2
nd
in the
Pascal VOC 2010 challenge [
EVGW
+
10
] is described
in [
CS10
]. The system makes heavy use of the multi-
cue contour detector globalPb [
MAFM08
] and needs
about
10
GB of main memory [CS11].
3) Random Walks:
Random walks belong to the
graph-based image segmentation algorithms. Random
walk image segmentation usually works as follows:
Seed points are placed on the image for the different
objects in the image. From every single pixel, the
probability to reach the different seed points by a
random walk is calculated. This is done by taking
image gradients as described in Section
V-A
for HOG
features. The class of the pixel is the class of which a
seed point will be reached with highest probability. At
rst, this is an interactive segmentation method, but it
can be extended to be non-interactive by using another
segmentation methods output as seed points.
4) Active Contour Models:
Active contour models
(ACMs) are algorithms which segment images roughly
along edges, but also try to nd a border which is
smooth. This is done by dening a so called
energy
function
which will be minimized. They were initially
described in [
KWT88
]. ACMs can be used to segment
an image or to rene segmentation as it was done
in [AM98] for brain MR images.
5) Watershed Segmentation:
The watershed algo-
rithm takes a grayscale image and interprets it as a
height map. Low values are catchment basins and
the higher values between two neighboring catchment
basins is the watershed. The catchment basins should
contain what the developer wants to capture. This
implies that those areas must be dark on grayscale
images. The algorithm starts to ll the basins from
the lowest point. When two basins are connected, a
watershed is found. The algorithm stops when the
highest point is reached.
A detailed description of the watershed segmentation
algorithm is given in [RM00].
The watershed segmentation was used in [
JLD03
] to
segment white blood cells. As the authors describe,
the segmentation by watershed transform has two
aws: Over-segmentation due to local minima and thick
watersheds due to plateaus.
7
C. Random Decision Forests
Random Decision Forests were rst proposed
in [
Ho95
]. This type of classier applies techniques
called
ensemble learning
, where multiple classiers
are trained and a combination of their hypotheses is
used. One ensemble learning technique is the
random
subspaces
method where each classier is trained
on a random subspace of the feature space. Another
ensemble learning technique is
bagging
, which is
training the trees on random subsets of the training set.
In the case of Random Decision Forests, the classiers
are decision trees. A decision tree is a tree where each
inner node uses one or more features to decide in which
branch to descend. Each leaf is a class.
One strength of Random Decision Forests compared
tomanyotherclassierslikeSVMsandneuralnetworks
is that the scale of measure of the features (nominal,
ordinal, interval, ratio) can be arbitrary. Another advan-
tage of Random Decision Forests compared to SVMs,
for example, is the speed of training and classication.
Decision trees were extensively studied in the past
20 years and a multitude of training algorithms have
been proposed (e.g. ID3 in [
Qui86
], C4.5 in [
Qui93
]).
Possible training hyperparameters are the measure to
evaluate the Ô¨Ågoodness of splitÔ¨Ç [
Min89
], the number of
decision trees being used, and if the depth of the trees
is restricted. Typically in the context of classication,
decision trees are trained by adding new nodes until
each leaf contains only nodes of a single class or until it
is not possible to split further. This is called a
stopping
criterion
.
There are two typical training modes:
Central axis
projection
and
perceptron training
. In training, for
each node a hyperplane is searched which is optimal
according to an error function.
Random Decision Forests with texton features (see
Section
V-A
6) are applied in [
SJC08
] for segmentation.
In the [
MSC
] dataset, they report a per-pixel accuracy
rate of
66
:
9
%
for their best system. This system
requires
415
ms
for the segmentation of
320
px

213
px
images on a single
2
:
7
GHz
core. On the Pascal
VOC 2007 dataset, they report an average per-pixel
accuracy for their best segmentation system of
42
%.
An excellent introduction to Random Decision
Forests for semantic segmentation is given by [
SCZ08
].
D. SVMs
SVMs are well-studied binary classiers which can
be described by ve central ideas. For those ideas, the
training data is represented as
(
x
i
;y
i
)
where
x
i
is the
feature vector and
y
i
2 f
1
;
1
g
the binary label for
training example
i
2 f
1
;:::;m
g
.
1)
If data is linearly separable, it can be separated
by a hyperplane. There is one hyperplane which
maximizes the distance to the next datapoints
(
supportvectors
).Thishyperplaneshouldbetaken:
minimize
w
;b
1
2
k
w
k
2
s.t.
8
m
i
=1
y
i

(
h
w
;
x
i
i
+
b
)
|
{z
}
sgn
applied to this gives the classication

1
2)
Even if the underlying process which generates the
features for the two classes is linearly separable,
noise can make the data not separable. The intro-
duction of
slack variables
to relax the requirement
of linear separability solves this problem. The
trade-off between accepting some errors and a
more complex model is weighted by a parameter
C
2
R
+
0
. The bigger
C
, the more errors are
accepted. The new optimization problem is:
minimize
w
1
2
k
w
k
2
+
C

m
X
i
=1
Àò
i
s.t.
8
m
i
=1
y
i

(
h
w
;
x
i
i
+
b
)

1

Àò
i
Note that
0

Àò
i

1
means that the data point
is within the margin, whereas
Àò
i

1
means it is
misclassied. An SVM with
C >
0
is also called
a
soft-margin SVM
.
3)
The primal problem is to nd the normal vector
w
and the bias
b
. The dual problem is to express
w
as a linear combination of the training data
x
i
:
w
=
m
X
i
=1

i
y
i
x
i
where
y
i
2 f
1
;
1
g
represents the class of the
training example and

i
are Lagrange multipliers.
The usage of Lagrange multipliers is explained
with some examples in [
Smi04
]. The usage of the
Lagrange multipliers

i
changes the optimization
problem depend on the

i
which are weights for
the feature vectors. It turns out that most

i
will
be zero. The non-zero weighted vectors are called
support vectors
.
The optimization problem is now, according
to [Bur98]:
maximize

i
m
X
i
=1

i

1
2
m
X
i
=1
m
X
j
=1

i

j
y
i
y
j
h
x
i
;
x
j
i
s.t.
8
m
i
=1
0


i

C
s.t.
m
X
i
=1

i
y
i
= 0
8
4)
Not every dataset is linearly separable. This prob-
lem is approached by transforming the feature
vectors
x
with a non-linear mapping

into
a higher dimensional (probably
1
-dimensional)
space. As the feature vectors
x
are only used
within scalar product
h
x
i
;
x
j
i
, it is not necessary
to do the transformation. It is enough to do the
calculation
K
(
x
i
;
x
j
) =
h
x
i
;
x
j
i
This function
K
is called a
kernel
. The idea of
never explicitly transforming the vectors
x
i
to the
higher dimensional space is called the
kernel trick
.
Common kernels include the polynomial kernel
K
P
(
x
i
;
x
j
) = (
h
x
i
;
x
j
i
+
r
)
p
of degree
p
and coefcient
r
, the Gaussian radial
basis function (RBF) kernel
K
Gauss
(
x
i
;
x
j
) =
e


k
x
i

x
j
k
2
2
Àô
2
and the sigmoid kernel
K
tanh
(
x
i
;
x
j
) = tanh(

h
x
i
;
x
j
i
r
)
where the parameter

determines how much
inuence single training examples have.
5)
The described SVMs can only distinguish between
two classes. Common strategies to expand those
binary classiers to multi-class classication is
the
one-vs-all
and the
one-vs-one
strategy. In the
one-vs-all strategy
n
classiers have to be trained
which can distinguish one of the
n
classes against
all other classes. In the one-vs-one strategy
n
2

n
2
classiers are trained; one classier for each pair
of classes.
A detailed description of SVMs can be found
in [Bur98].
SVMs are used by [
YHRF12
] on the 2009 and 2010
PASCAL segmentation challenge [
EVGW
+
10
]. They
did not hand their classier in to the challenge itself,
but calculated an average rank of 7 among the different
categories.
[
FGMR10
] also used an SVM based method with
HOG features and achieved the 7
th
rank in the 2010
PASCAL segmentation challenge by mean accuracy. It
needs about
2
s on a
2
:
8
GHz 8-core Intel processor.
E. Markov Random Fields
MRFs are undirected probabilistic graphical models
which are wide-spread model in computer vision. The
overall idea of MRFs is to assign a random variable for
each feature and a random variable for each pixel which
x
1
x
2
x
3
x
4
x
5
x
6
x
7
x
8
x
9
y
1
y
2
y
3
y
4
y
5
y
6
y
7
y
8
y
9
x
1
x
2
x
3
x
4
x
5
x
6
x
7
x
8
x
9
y
1
y
2
y
3
y
4
y
5
y
6
y
7
y
8
y
9
Figure 3:
CRF with 4-neighborhood. Each node
x
i
represents a pixel and each node
y
i
represents
a label.
gets labeled as shown in Figure 3. For example, a MRF
which is trained on images of the size
224
px

224
pixel
and gets the raw RGB values as features has
224

224

3
|
{z
}
input
+224

224
|
{z
}
output
= 200704
random variables. Those random variables are condi-
tionally independent, given their local neighborhood.
These (in)dependencies can be expressed with a graph.
Let
G
= (
V
;
E
)
be the associated undirected graph
of an MRF and
C
be the set of all maximal cliques in
that graph. Nodes represent random variables
x
;
y
and
edges represent conditional dependencies. Just like in
he 4-neighborhood [
SWRC06
] and the 8-neighborhood
are reasonable choices for constructing the graph.
Typically, random variables
y
represent the class of a
single pixel, random variables
x
represent a pixel values
and edges represent pixel neighborhood in computer
vision problems segmentation problems where MRFs
are used. Accordingly, the random variables
y
live
on
1
;:::;
nr of classes
and the random variables
x
typically live on
0
;:::;
255
or
[0
;
1]
.
The probability of
x
;
y
can be expressed as
P
(
x
;
y
) =
1
Z
e

E
(
x
;
y
)
where
Z
=
P
x
;
y
e

E
(
x
;
y
)
is a normalization term
called the
partition function
and
E
is called the
energy
function
. A common choice for the energy function is
E
(
x
;
y
) =
X
c
2C
 
c
(
x
;
y
)
where
 
is called a
clique potential
. One choice for
cliques of size two
x
;
y
= (
x
1
;x
2
)
is [KP06]
 
c
(
x
1
;x
2
) =
w
(
x
1
;x
2
) =
(
+
w
if
x
1
6
=
x
2

w
if
x
1
=
x
2
According to [
Mur12
], the most common way of
inference over the posterior MRF in computer vision
problems is Maximum A Posteriori (MAP) estimation.
9
Detailed introductions to MRFs are given by
[
BKR11
], [
Mur12
]. MRFs are used by [
ZBS01
] and
[MSB12] for image segmentation.
F. Conditional Random Fields
CRFs are MRFs where all clique potentials are
conditioned on input features [
Mur12
]. This means,
instead of learning the distribution
P
(
y
;
x
)
, the task
is reformulated to learn the distribution
P
(
y
j
x
)
. One
consequence of this reformulation is that CRFs need
much less parameters as the distribution of
x
does
not have to be estimated. Another advantage of CRFs
compared to MRFs is that no distribution assumption
about
x
has to be made.
A CRF has the partition function
Z
:
Z
(
x
) =
X
y
P
(
x
;
y
)
and joint probability distribution
P
(
y
j
x
) =
1
Z
(
x
)
Y
c
2C
 
c
(
y
c
j
x
)
The simplest way to dene the clique potentials
 
is
the count of the class
y
c
given
x
added with a positive
smoothing constant to prevent the complete term from
getting zero.
CRFs as described in [
LRKT09
] have reached top
performance in PASCAL VOC 2010 [
VOC10
] and
are also used in [
HZCP04
], [
SWRC06
] for semantic
segmentation.
A method similar to CRFs was proposed
in [
GBVdW
+
10
]. The system of Gonfaus et.al.
ranked 1
st
by mean accuracy in the segmentation task
of the PASCAL VOC 2010 challenge [EVGW
+
10].
An introduction to CRFs is given by [SM11].
G. Post-processing methods
Post-processing rene a found segmentation and
remove obvious errors. For example, the morphological
operations
opening
and
closing
can remove noise. The
opening operation is a dilation followed by a erosion.
This removes tiny segments. The closing operation is a
erosion followed by a dilation. This removes tiny gaps
in otherwise lled regions. They were used in [
CLP98
]
for biomedical image segmentation.
Another way of renement of the found segmentation
is by adjusting the segmentation to match close edges.
This was used in [
BBMM11
] with an ultra-metric
contour map [AMFM09].
Active contour models are another example of a
post-processing method [KWT88].
VI. N
EURAL
N
ETWORKS FOR
S
EMANTIC
S
EGMENTATION
Articial neural networks are classiers which are
inspired by biologic neurons. Every single articial
neuron has some inputs which are weighted and sumed
up. Then, the neuron applies a so called
activation
function
to the weighted sum and gives an output. Those
neurons can take either a feature vector as input or the
output of other neurons. In this way, they build up
feature hierarchies.
The parameters they learn are the
weights
w
2
R
.
They are learned by gradient descent. To do so, an error
function ≈† usually cross-entropy or mean squared error
≈† is necessary. For the gradient descent algorithm, one
sees the labeled training data as given, the weights
as variables and the error function as a surface in
this weight-space. Minimizing the error function in the
weight space adapts the neural network to the problem.
There are lots of ideas around neural networks like
regularization, better optimization algorithms, automat-
ically building up architectures, design choices for
activation functions. This is not explained in detail here,
but some of the mayor breakthroughs are outlined.
CNNs are neural networks which learn image lters.
They drastically reduce the number of parameters which
have to be learned while being still general enough for
the problem domain of images. This was shown by Alex
Krizhevsky et al. in [
KSH12
]. One major idea was a
clever regularization called
dropout training
, which set
the output of neurons while training randomly to zero.
Another contribution was the usage of an activation
function called
rectied linear unit
:
'
ReLU
(
x
) = max(0
;x
)
Those are much faster to train than the commonly used
sigmoid activation functions
'
Sigmoid
(
x
) =
1
e

x
+1
Krizhevsky et al. implemented those ideas and partici-
pated in the ImageNet Large-Scale Visual Recognition
Challenge (ILSVRC). The best other system, which
used SIFT features and Fisher Vectors, had a perfor-
mance of about
25
:
7
%
while the network by Alex
Krizhevsky et al. got
17
:
0
%
error rate on the ILSVRC-
2010 dataset. As a preprocessing step, they downsam-
pled all images to a xed size of
256
px

256
px
before
they fed the features into their network. This network
is commonly known as
AlexNet
.
Since AlexNet was developed, a lot of different
neural networks have been proposed. One interesting
example is [
PC13
], where a recurrent CNN for semantic
segmentation is presented.
10
Another notable paper is [
LSD14
]. The algorithm
presented there makes use of a classifying network such
as AlexNet, but applies the complete network as an
image lter. This way, each pixel gets a probability
distribution for each of the trained classes. By taking
the most likely class, a semantic segmentation can be
done with arbitrary image sizes.
A very recent publication by Dai et al. [
DHS15
]
showed that segmentation with much deeper networks
is possible and achieves better results.
More detailed explanations to neural networks for
visual recognition is given by [LKJ15].
VII. P
OSSIBLE
P
ROBLEMS IN THE
D
ATA FOR
S
EGMENTATION ALGORITHMS
Different segmentation workows have different
problems. However, there are a couple of special cases
which should be tested. Those cases might not occur
often in the training data, but it could still happen in
the productive system.
I am not aware of any systematic work which exam-
ined the inuence of problems such as the following.
A. Lens Flare
Lens are is the effect of light getting scattered in
the lens system of the camera. The testing data set of
the KITTI road evaluation benchmark [
FKG13
] has a
couple of photos with this problem. Figure 4(a) shows
an extreme example of lens are.
B. Vignetting
Vignetting is the effect of a photograph getting darker
in the corners. This can have many reasons, for example
lters on the camera blocking light at the corners.
C. Blurred images
Images can be blurred for a couple of reasons. A
problem with the lenses mechanics, focusing on the
wrong point, too quick movement, smoke or foam. One
example of a blurred image is Figure 4(c), which was
taken during an in vivo porcine procedure of diaphragm
dissection. The smoke was caused by cauterization.
D. Other Problems
If the following effects can occur at all and if they
are problems depends heavily on the problem domain
and the used model.
1) Partial Occlusions:
Segmentation systems which
employ a model of the objects which should be
segmented might suffer from partial occlusions.
(a)
 Lens Flare
Image by [Hus07]
(b)
 Vignetting
Image by [Man12]
(c)
 Smoke by cauterization
Image by [GVSY13]
(d)
 Camouage
Image by [Kaf07]
(e) Transparency
(f) Viewpoint
Figure 4:
Examples of images which might cause
semantic segmentation systems to fail.
2) Camouage:
Some objects, like animals in the
wild,activelytrytohide(seeFigure4(d)asanexample).
In other cases it might just be bad luck that objects
are hard for humans to detect. This problem has two
interesting aspects: On the one hand, the segmenting
system might suffer from the same problems as humans
do. On the other hand, the segmenting system might be
better than humans are, but it is forced to learn from
images labeled by humans. If the labels are wrong, the
system is forced to learn something wrong.
3) Semi-transparent Occlusion:
Some objects like
drinking glasses can be visible and still leave the object
behind them visible as shown in Figure 4(e). This is
mainly a denition problem: Is the seen pixel the glass
label or the smartphone label?
4) Viewpoints:
Changes in viewpoints can be a
problem, if they don't occur in the training data. For
example, an image captioning system which was trained
on photographs of professional photographers might
not have photos from the point of view of a child. This
is visualized in Figure 4(f).
11
VIII. D
ISCUSSION
Ohta et al. wrote [
OKS78
] 38 years ago. It is one
of the rst papers mentioning semantic segmentation.
In this time, a lot of work was done and many
different directions have been explored. Different kinds
of semantic segmentation have emerged.
This paper presents a taxonomy of those kinds
of semantic segmentation and a brief overview of
completely automatic, passive, semantic segmentation
algorithms.
Future work includes a comparative study of
those algorithms on publicly available dataset such
as the ones presented in Table I. Another open
question is the inuence of the problems described
in Section VII. This could be done using a subset of the
thousands of images of Wikipedia Commons, such as
https://commons.wikimedia.org/wiki/Category:Blurring
for blurred images.
A combination of different classiers in an ensemble
would be an interesting option to explore in order to
improve accuracy. Another direction which is currently
studied is combining classiers such as neural networks
with CRFs [ZJRP
+
15].
R
EFERENCES
[AM98]
M. S. Atkins and B. T. Mackiewich, Ô¨ÅFully
automatic segmentation of the brain in
mri,Ô¨Ç
Medical Imaging, IEEE Transactions
on
, vol. 17, no. 1, pp. 98≈í107, Feb. 1998.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=668699
[AMFM09]
P. Arbelaez, M. Maire, C. Fowlkes, and
J. Malik, Ô¨ÅFrom contours to regions: An
empirical evaluation,Ô¨Ç in
Computer Vision and
Pattern Recognition, 2009. CVPR 2009. IEEE
Conference on
. IEEE, Jun. 2009, pp. 2294≈í2301.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=5206707
[AP11]
G. Azzopardi and N. Petkov, Ô¨ÅDetection of
retinal vascular bifurcations by trainable v4-like
lters,Ô¨Ç in
Computer Analysis of Images and
Patterns
. Springer, 2011, pp. 451≈í459. [Online].
Available: http://www
:
cs
:
rug
:
nl/~imaging/databases/
retina_database/retinalfeatures_database
:
html
[BBMM11]
T. Brox, L. Bourdev, S. Maji, and J. Malik,
Ô¨ÅObject segmentation by alignment of poselet
activations to image contours,Ô¨Ç in
Computer Vision
and Pattern Recognition (CVPR), 2011 IEEE
Conference on
. IEEE, Jun. 2011, pp. 2225≈í2232.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=5995659
[BJ00]
Y. Boykov and M.-P. Jolly, Ô¨ÅInteractive organ
segmentation using graph cuts,Ô¨Ç in
Medical Image
Computing and Computer-Assisted Intervention≈í
MICCAI 2000
. Springer, 2000, pp. 276≈í
286. [Online]. Available: http://link
:
springer
:
com/
chapter/10
:
1007/978-3-540-40899-4_28
[BKR11]
A. Blake, P. Kohli, and C. Rother,
Markov random
elds for vision and image processing
. Mit Press,
2011.
[BKTT15]
S. Bittel, V. Kaiser, M. Teichmann, and M. Thoma,
Ô¨ÅPixel-wise segmentation of street with neural
networks,Ô¨Ç
arXiv preprint arXiv:1511.00513
, 2015.
[Online]. Available: http://arxiv
:
org/abs/1511
:
00513
[BMBM10]
L. Bourdev, S. Maji, T. Brox, and J. Malik,
Ô¨ÅDetecting people using mutually consistent
poselet activations,Ô¨Ç in
Computer Vision≈íECCV
2010
. Springer, 2010, pp. 168≈í181. [Online].
Available: http://link
:
springer
:
com/chapter/10
:
1007/
978-3-642-15567-3_13#page-1
[Bur98]
C. J. Burges, Ô¨ÅA tutorial on support vector machines
forpatternrecognition,Ô¨Ç
Dataminingandknowledge
discovery
, vol. 2, no. 2, pp. 121≈í167, 1998.
[BVZ01]
Y. Boykov, O. Veksler, and R. Zabih, Ô¨ÅFast
approximate energy minimization via graph cuts,Ô¨Ç
Pattern Analysis and Machine Intelligence, IEEE
Transactions on
, vol. 23, no. 11, pp. 1222≈í1239,
2001. [Online]. Available: http://ieeexplore
:
ieee
:
org/
xpls/abs_all
:
jsp?arnumber=969114
[CDF
+
04]
G. Csurka, C. Dance, L. Fan, J. Willamowski,
and C. Bray, Ô¨ÅVisual categorization with bags of
keypoints,Ô¨Ç in
Workshop on statistical learning in
computer vision, ECCV
, vol. 1, no. 1-22. Prague,
2004, pp. 1≈í2.
[CJSW01]
H.-D. Cheng, X. Jiang, Y. Sun, and J. Wang,
Ô¨ÅColorimagesegmentation:advancesandprospects,Ô¨Ç
Pattern recognition
, vol. 34, no. 12, pp. 2259≈í2281,
2001.
[CLP98]
C. W. Chen, J. Luo, and K. J. Parker, Ô¨ÅImage
segmentation via adaptive k-mean clustering and
knowledge-based morphological operations with
biomedical applications,Ô¨Ç
Image Processing, IEEE
Transactions on
, vol. 7, no. 12, pp. 1673≈í1683, Dec.
12
1998. [Online]. Available: http://ieeexplore
:
ieee
:
org/
xpls/abs_all
:
jsp?arnumber=730379
[CM02]
D. Comaniciu and P. Meer, Ô¨ÅMean shift: A
robust approach toward feature space analysis,Ô¨Ç
Pattern Analysis and Machine Intelligence, IEEE
Transactions on
, vol. 24, no. 5, pp. 603≈í619, 2002.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpl/
login
:
jsp?tp=&arnumber=1000236
[COWR11]
C. Chen, J. Ozolek, W. Wang, and G. K. Rohde,
Ô¨ÅA pixel classication system for segmenting
biomedical images using intensity neighborhoods
and dimension reduction,Ô¨Ç in
Biomedical Imaging:
From Nano to Macro, 2011 IEEE International
Symposium on
. IEEE, 2011, pp. 1649≈í1652.
[Online]. Available: https://www
:
andrew
:
cmu
:
edu/
user/gustavor/chen_isbi_11
:
pdf
[CP08]
G. Csurka and F. Perronnin, Ô¨ÅA simple high
performance approach to semantic segmentation.Ô¨Ç
in
BMVC
, 2008, pp. 1≈í10. [Online]. Avail-
able: http://www
:
xrce
:
xerox
:
com/layout/set/print/
content/download/16654/118653/le/2008-023
:
pdf
[CRSS]
A. Cohen, E. Rivlin, I. Shimshoni, and
E. Sabo, Ô¨ÅColon crypt segmentation website.Ô¨Ç [On-
line]. Available: http://mis
:
haifa
:
ac
:
il/~ishimshoni/
SegmentCrypt/Download
:
htm
[CRSS14]
≈†≈†, Ô¨ÅMemory based active contour algorithm
using pixel-level classied images for colon crypt
segmentation,Ô¨Ç
Computerized Medical Imaging
and Graphics
, Nov. 2014. [Online]. Available:
http://mis
:
haifa
:
ac
:
il/~ishimshoni/SegmentCrypt/
Active%20contour%20based%20on%20pixel-
level%20classied%20image%20for%20colon%
20crypts%20segmentation
:
pdf
[CS10]
J. Carreira and C. Sminchisescu, Ô¨ÅConstrained
parametric min-cuts for automatic object segmenta-
tion,Ô¨Ç in
Computer Vision and Pattern Recognition
(CVPR), 2010 IEEE Conference on
. IEEE, 2010,
pp. 3241≈í3248.
[CS11]
≈†≈†, Ô¨ÅCpmc: Constrained parametric min-cuts for
automatic object segmentation,Ô¨Ç Feb. 2011. [Online].
Available: http://www
:
maths
:
lth
:
se/matematiklth/
personal/sminchis/code/cpmc/
[CSI
+
09]
M. E. Celebi, G. Schaefer, H. Iyatomi, W. V.
Stoecker, J. M. Malters, and J. M. Grichnik, Ô¨ÅAn
improved objective evaluation measure for border
detection in dermoscopy images,Ô¨Ç
Skin Research
and Technology
, vol. 15, no. 4, pp. 444≈í450, 2009.
[Online]. Available: http://arxiv
:
org/abs/1009
:
1020
[CSM09]
L. P. Coelho, A. Shariff, and R. F. Murphy, Ô¨ÅNuclear
segmentation in microscope cell images: a hand-
segmented dataset and comparison of algorithms,Ô¨Ç
in
Biomedical Imaging: From Nano to Macro,
2009. ISBI'09. IEEE International Symposium on
.
IEEE, 2009, pp. 518≈í521. [Online]. Available:
http://murphylab
:
web
:
cmu
:
edu/data
[CXGS12]
M. D. Collins, J. Xu, L. Grady, and V. Singh,
Ô¨ÅRandom walks based multi-image segmentation:
Quasiconvexity results and gpu-based solutions,Ô¨Ç
in
Computer Vision and Pattern Recognition
(CVPR), 2012 IEEE Conference on
. IEEE,
2012, pp. 1656≈í1663. [Online]. Available: http:
//pages
:
cs
:
wisc
:
edu/~jiaxu/pub/rwcoseg
:
pdf
[DHS15]
J. Dai, K. He, and J. Sun, Ô¨ÅInstance-aware seman-
tic segmentation via multi-task network cascades,Ô¨Ç
arXiv preprint arXiv:1512.04412
, 2015.
[DT05]
N. Dalal and B. Triggs, Ô¨ÅHistograms of oriented
gradients for human detection,Ô¨Ç in
Computer
Vision and Pattern Recognition, 2005. CVPR
2005. IEEE Computer Society Conference on
,
vol. 1, June 2005, pp. 886≈í893 vol. 1.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=1467360
[EVGW
+
a]
M. Everingham, L. Van Gool, C. K. I.
Williams, J. Winn, and A. Zisserman, Ô¨ÅThe
PASCAL Visual Object Classes Challenge
2007 (VOC2007) Results,Ô¨Ç http://www.pascal-
network.org/challenges/VOC/voc2007/workshop/index.html.
[Online]. Available: http://host
:
robots
:
ox
:
ac
:
uk:
8080/pascal/VOC/voc2007/index
:
html
[EVGW
+
b]
≈†≈†, Ô¨ÅThe PASCAL Visual Object Classes Chal-
lenge 2012 (VOC2012) Results,Ô¨Ç http://www.pascal-
network.org/challenges/VOC/voc2012/workshop/index.html.
[Online]. Available: http://host
:
robots
:
ox
:
ac
:
uk:
8080/pascal/VOC/voc2012/index
:
html
[EVGW
+
10]
M. Everingham, L. Van Gool, C. K. Williams,
J.Winn,andA.Zisserman,Ô¨ÅThepascalvisualobject
classes (voc) challenge,Ô¨Ç
International journal of
computer vision
, vol. 88, no. 2, pp. 303≈í338, 2010.
[EVGW
+
12]
M. Everingham, L. Van Gool, C. K. I. Williams,
J. Winn, and A. Zisserman, Ô¨ÅVisual object
classes challenge 2012 (voc2012),Ô¨Ç 2012. [Online].
Available: http://host
:
robots
:
ox
:
ac
:
uk:8080/pascal/
VOC/voc2012/index
:
html
[Fel]
P. F. Felzenszwalb, Ô¨ÅGraph based im-
age segmentation.Ô¨Ç [Online]. Available: http:
//cs
:
brown
:
edu/~pff/segment/
[FGMR10]
P. F. Felzenszwalb, R. B. Girshick, D. McAllester,
and D. Ramanan, Ô¨ÅObject detection with discrimina-
tively trained part-based models,Ô¨Ç
Pattern Analysis
and Machine Intelligence, IEEE Transactions on
,
vol. 32, no. 9, pp. 1627≈í1645, 2010.
[FH04]
P. F. Felzenszwalb and D. P. Huttenlocher,
Ô¨ÅEfcient graph-based image segmentation,Ô¨Ç
International Journal of Computer Vision
,
vol. 59, no. 2, pp. 167≈í181, 2004. [Online].
Available: http://link
:
springer
:
com/article/10
:
1023/
B:VISI
:
0000022288
:
19776
:
77
[FKG13]
J. Fritsch, T. Kuehnl, and A. Geiger, Ô¨ÅA
new performance measure and evaluation
benchmark for road detection algorithms,Ô¨Ç in
International Conference on Intelligent Transporta-
tion Systems (ITSC)
, 2013. [Online]. Available:
http://www
:
cvlibs
:
net/datasets/kitti/eval_road
:
php
[GBVdW
+
10]
J. M. Gonfaus, X. Boix, J. Van de Weijer, A. D.
Bagdanov, J. Serrat, and J. Gonzalez, Ô¨ÅHarmony po-
tentials for joint classication and segmentation,Ô¨Ç in
Computer Vision and Pattern Recognition (CVPR),
2010 IEEE Conference on
. IEEE, 2010, pp. 3280≈í
3287.
[GRC
+
08]
S. Gould, J. Rodgers, D. Cohen, G. Elidan, and
D. Koller, Ô¨ÅMulti-class segmentation with relative
location prior,Ô¨Ç
International Journal of Computer
Vision
, vol. 80, no. 3, pp. 300≈í316, Apr. 2008.
[GVSY13]
S. Giannarou, M. Visentini-Scarzanella, and G.-
Z. Yang, Ô¨ÅProbabilistic tracking of afne-invariant
anisotropic regions,Ô¨Ç
Pattern Analysis and Machine
Intelligence, IEEE Transactions on
, vol. 35, no. 1,
pp. 130≈í143, 2013.
[Har75]
J. A. Hartigan,
Clustering algorithms
. John Wiley
& Sons, Inc., 1975.
[HDT02]
C. Huang, L. Davis, and J. Townshend, Ô¨ÅAn
assessment of support vector machines for land
coverclassication,Ô¨Ç
InternationalJournalofremote
sensing
, vol. 23, no. 4, pp. 725≈í749, 2002.
[HHR01]
S. Hu, E. Hoffman, and J. Reinhardt, Ô¨ÅAutomatic
lung segmentation for accurate quantitation of
volumetric x-ray ct images,Ô¨Ç
Medical Imaging, IEEE
13
Transactions on
, vol. 20, no. 6, pp. 490≈í498, Jun.
2001.
[HJBJ
+
96]
A. Hoover, G. Jean-Baptiste, X. Jiang, P. J.
Flynn, H. Bunke, D. B. Goldgof, K. Bowyer,
D. W. Eggert, A. Fitzgibbon, and R. B.
Fisher, Ô¨ÅAn experimental comparison of range
image segmentation algorithms,Ô¨Ç
Pattern Analysis
and Machine Intelligence, IEEE Transactions
on
, vol. 18, no. 7, pp. 673≈í689, Jul. 1996.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=506791
[Ho95]
T. K. Ho, Ô¨ÅRandom decision forests,Ô¨Ç in
Document Analysis and Recognition, 1995.,
Proceedings of the Third International Conference
on
, vol. 1. IEEE, 1995, pp. 278≈í282.
[Online]. Available: http://ect
:
bell-labs
:
com/who/
tkh/publications/papers/odt
:
pdf
[Hus07]
Hustvedt, Ô¨ÅFile:cctv lens are.jpg,Ô¨Ç Wikipedia
Commons, Nov. 2007. [Online]. Avail-
able: https://commons
:
wikimedia
:
org/wiki/File:
CCTV_Lens_are
:
jpg
[HZCP04]
X. He, R. Zemel, and M. Carreira-Perpindn,
Ô¨ÅMultiscale conditional random elds for image
labeling,Ô¨Ç in
Computer Vision and Pattern
Recognition, 2004. CVPR 2004. Proceedings
of the 2004 IEEE Computer Society Conference
on
, vol. 2, Jun. 2004, pp. II≈í695≈íII≈í702 Vol.2.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpl/
login
:
jsp?tp=&arnumber=1315232
[JLD03]
K. Jiang, Q.-M. Liao, and S.-Y. Dai, Ô¨ÅA novel white
blood cell segmentation scheme using scale-space
ltering and watershed clustering,Ô¨Ç in
Machine
Learning and Cybernetics, 2003 International
Conference on
, vol. 5, Nov 2003, pp. 2820≈í2825
Vol.5. [Online]. Available: http://ieeexplore
:
ieee
:
org/
xpl/login
:
jsp?tp=&arnumber=1260033
[Kaf07]
L. Kaffer, Ô¨ÅFile:great male leopard in south afrika-
jd.jpg,Ô¨Ç Wikipedia Commons, Jul. 2007. [Online].
Available:https://commons
:
wikimedia
:
org/wiki/File:
Great_male_Leopard_in_South_Afrika-JD
:
JPG
[KKV
+
14]
V. Kalesnykiene, J.-k. Kamarainen, R. Voutilainen,
J. Pietil√§, H. K√§lvi√§inen, and H. Uusitalo,
Ô¨ÅDiaretdb1 diabetic retinopathy database and
evaluation protocol,Ô¨Ç 2014. [Online]. Available:
http://www2
:
it
:
lut
:
/project/imageret/diaretdb1/
[KP92]
J. M. Kasson and W. Plouffe, Ô¨ÅAn analysis of
selected computer interchange color spaces,Ô¨Ç
ACM
Transactions on Graphics (TOG)
, vol. 11, no. 4, pp.
373≈í405, 1992.
[KP06]
Z. Kato and T.-C. Pong, Ô¨ÅA markov random
eld image segmentation model for color
textured images,Ô¨Ç
Image and Vision Computing
,
vol. 24, no. 10, pp. 1103≈í1114, 2006. [Online].
Available: http://www
:
sciencedirect
:
com/science/
article/pii/S0262885606001223
[KSH12]
A. Krizhevsky, I. Sutskever, and G. E. Hinton,
Ô¨ÅImagenet classication with deep convolutional
neural networks,Ô¨Ç in
Advances in neural information
processing systems
, 2012, pp. 1097≈í1105.
[KWT88]
M. Kass, A. Witkin, and D. Terzopoulos,
Ô¨ÅSnakes: Active contour models,Ô¨Ç
International
journal of computer vision
, vol. 1, no. 4, pp.
321≈í331, Jan. 1988. [Online]. Available: http:
//link
:
springer
:
com/article/10
:
1007/BF00133570
[LKJ15]
F.-F. Li, A. Karpathy, and J. Johnson,
Ô¨ÅCS231n: Convolutional neural networks for
visual recognition,Ô¨Ç 2015. [Online]. Available:
http://cs231n
:
stanford
:
edu/
[Low04]
D. Lowe, Ô¨ÅDistinctive image features from scale-
invariant keypoints,Ô¨Ç
International Journal of
Computer Vision
, vol. 60, no. 2, pp. 91≈í110, 2004.
[Online]. Available: http://dx
:
doi
:
org/10
:
1023/B%
3AVISI
:
0000029664
:
99615
:
94
[LRAL08]
A. Levin, A. Rav-Acha, and D. Lischinski,
Ô¨ÅSpectral matting,Ô¨Ç
Pattern Analysis and
Machine Intelligence, IEEE Transactions on
,
vol. 30, no. 10, pp. 1699≈í1712, 2008.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=4547428
[LRKT09]
L. Ladick√Ω, C. Russell, P. Kohli, and P. Torr,
Ô¨ÅAssociative hierarchical crfs for object class image
segmentation,Ô¨Ç in
Computer Vision, 2009 IEEE 12th
International Conference on
, 2009, pp. 739≈í746.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=5459248
[LSD14]
J. Long, E. Shelhamer, and T. Darrell, Ô¨ÅFully
convolutional networks for semantic segmentation,Ô¨Ç
arXiv preprint arXiv:1411.4038
, 2014. [Online].
Available: http://arxiv
:
org/abs/1411
:
4038
[MAFM08]
M. Maire, P. Arbelaez, C. Fowlkes, and
J. Malik, Ô¨ÅUsing contours to detect and localize
junctions in natural images,Ô¨Ç in
Computer Vision
and Pattern Recognition, 2008. CVPR 2008.
IEEE Conference on
, June 2008, pp. 1≈í8.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=4587420
[Man12]
M. Manske, Ô¨ÅFile:randabschattung mikroskop
kamera 6.jpg,Ô¨Ç Wikipedia Com-
mons, Dec. 2012. [Online]. Avail-
able: https://commons
:
wikimedia
:
org/wiki/File:
Randabschattung_Mikroskop_Kamera_6
:
JPG
[MBLAGJ
+
07]
S. Maldonado-Bascon, S. Lafuente-Arroyo, P. Gil-
Jimenez, H. Gomez-Moreno, and F. Lopez-
Ferreras, Ô¨ÅRoad-sign detection and recognition
based on support vector machines,Ô¨Ç
Intelligent
Transportation Systems, IEEE Transactions on
,
vol. 8, no. 2, pp. 264≈í278, Jun. 2007.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=4220659
[MBVLG02]
N. Moon, E. Bullitt, K. Van Leemput, and G. Gerig,
Ô¨ÅAutomatic brain and tumor segmentation,Ô¨Ç in
Med-
ical Image Computing and Computer-Assisted In-
tervention≈†MICCAI 2002
. Springer, 2002, pp.
372≈í379.
[MFTM01]
D. Martin, C. Fowlkes, D. Tal, and J. Malik,
Ô¨ÅA database of human segmented natural
images and its application to evaluating
segmentation algorithms and measuring ecological
statistics,Ô¨Ç in
Computer Vision, 2001. ICCV
2001. Proceedings. Eighth IEEE International
Conference on
, vol. 2. IEEE, 2001, pp. 416≈í423.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=937655
[MHMK
+
14]
L. Maier-Hein, S. Mersmann, D. Kondermann,
S. Bodenstedt, A. Sanchez, C. Stock, H. G.
Kenngott, M. Eisenmann, and S. Speidel, Ô¨ÅCan
masses of non-experts train highly accurate
image classiers?Ô¨Ç in
Medical Image Computing
and Computer-Assisted Intervention≈íMICCAI 2014
.
Springer, 2014, pp. 438≈í445. [Online]. Available:
http://opencas
:
webarchiv
:
kit
:
edu/?q=node/26
[Min89]
J. Mingers, Ô¨ÅAn empirical comparison of selection
measures for decision-tree induction,Ô¨Ç
Machine
Learning
, vol. 3, no. 4, pp. 319≈í342, 1989.
[Online]. Available: http://dx
:
doi
:
org/10
:
1023/A%
3A1022645801436
[MSB12]
G. Moser, S. B. Serpico, and J. A. Benediktsson,
Ô¨ÅMarkov random eld models for supervised land
14
cover classication from very high resolution
multispectral remote sensing images,Ô¨Ç in
Advances
in Radar and Remote Sensing (TyWRRS), 2012
Tyrrhenian Workshop on
. IEEE, 2012, pp. 235≈í
242. [Online]. Available: http://ieeexplore
:
ieee
:
org/
xpl/login
:
jsp?tp=&arnumber=6381135
[MSC]
Ô¨ÅObject class recognition image database.Ô¨Ç
[Online]. Available: http://research
:
microsoft
:
com/
vision/cambridge/recognition/
[MSR]
Ô¨ÅImage understanding - research data,Ô¨Ç
Microsoft Research. [Online]. Avail-
able: http://research
:
microsoft
:
com/en-us/projects/
objectclassrecognition/
[Mur12]
K. P. Murphy,
Machine learning: a probabilistic
perspective
. MIT press, 2012.
[OKS78]
Y.-i. Ohta, T. Kanade, and T. Sakai, Ô¨ÅAn analysis
system for scenes containing objects with substruc-
tures,Ô¨Ç in
Proceedings of the Fourth International
Joint Conference on Pattern Recognitions
, 1978, pp.
752≈í754.
[PAA
+
87]
S. M. Pizer, E. P. Amburn, J. D. Austin,
R. Cromartie, A. Geselowitz, T. Greer, B. ter
Haar Romeny, J. B. Zimmerman, and K. Zuiderveld,
Ô¨ÅAdaptive histogram equalization and its variations,Ô¨Ç
Computer vision, graphics, and image processing
,
vol. 39, no. 3, pp. 355≈í368, 1987. [Online].
Available: http://www
:
sciencedirect
:
com/science/
article/pii/S0734189X8780186X
[PC13]
P. H. Pinheiro and R. Collobert, Ô¨ÅRecurrent
convolutional neural networks for scene parsing,Ô¨Ç
arXiv preprint arXiv:1306.2795
, 2013. [Online].
Available: http://arxiv
:
org/abs/1306
:
2795v1
[PH05]
C. Pantofaru and M. Hebert, Ô¨ÅA
comparison of image segmentation algorithms,Ô¨Ç
Robotics Institute
, p. 336, 2005. [Online].
Available: http://riweb-backend
:
ri
:
cmu
:
edu/
pub
_
les/pub4/pantofaru
_
caroline
_
2005
_
1/
pantofaru_caroline_2005_1
:
pdf
[PS07]
A. Protiere and G. Sapiro, Ô¨ÅInteractive
image segmentation via adaptive weighted
distances,Ô¨Ç
Image Processing, IEEE Transactions
on
, vol. 16, no. 4, pp. 1046≈í1057, 2007.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=4130436
[PTN09]
N. Plath, M. Toussaint, and S. Nakajima, Ô¨ÅMulti-
class image segmentation using conditional random
elds and global classication,Ô¨Ç in
Proceedings
of the 26th Annual International Conference on
Machine Learning
. ACM, 2009, pp. 817≈í824.
[PXP00]
D. L. Pham, C. Xu, and J. L. Prince, Ô¨ÅA
survey of current methods in medical image
segmentation,Ô¨Ç
Annual Review of Biomedical
Engineering
, vol. 2, no. 1, pp. 315≈í337, 2000,
pMID: 11701515. [Online]. Available: http://
dx
:
doi
:
org/10
:
1146/annurev
:
bioeng
:
2
:
1
:
315
[Qui86]
J. R. Quinlan, Ô¨ÅInduction of decision trees,Ô¨Ç
Machine learning
, vol. 1, no. 1, pp. 81≈í106,
Aug. 1986. [Online]. Available: http://dx
:
doi
:
org/
10
:
1023/A%3A1022643204877
[Qui93]
≈†≈†,
C4.5:ProgramsforMachineLearning
,P.Lan-
gley, Ed. Morgan Kaufmann Publishers, Inc., 1993.
[RKB04]
C. Rother, V. Kolmogorov, and A. Blake, Ô¨ÅGrabcut:
Interactive foreground extraction using iterated
graph cuts,Ô¨Ç
ACM Transactions on Graphics
(TOG)
, vol. 23, no. 3, pp. 309≈í314, 2004. [Online].
Available: http://delivery
:
acm
:
org/10
:
1145/1020000/
1015720/p309-rother
:
pdf
[RM00]
J. B. Roerdink and A. Meijster, Ô¨ÅThe watershed
transform: Denitions, algorithms and paralleliza-
tion strategies,Ô¨Ç
Fundam. Inform.
, vol. 41, no. 1-2,
pp. 187≈í228, 2000.
[RM07]
J. Reynolds and K. Murphy, Ô¨ÅFigure-ground
segmentation using a hierarchical conditional
random eld,Ô¨Ç in
Computer and Robot
Vision, 2007. CRV '07. Fourth Canadian
Conference on
, May 2007, pp. 175≈í182.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=4228537
[RMBK06]
C. Rother, T. Minka, A. Blake, and V. Kolmogorov,
Ô¨ÅCosegmentation of image pairs by histogram
matching - incorporating a global constraint
into mrfs,Ô¨Ç in
Computer Vision and Pattern
Recognition, 2006 IEEE Computer Society
Conference on
, vol. 1, June 2006, pp. 993≈í
1000. [Online]. Available: http://ieeexplore
:
ieee
:
org/
xpls/abs_all
:
jsp?arnumber=1640859
[SAN
+
04]
J. Staal, M. D. Abr√†moff, M. Niemeijer,
M. Viergever, B. Van Ginneken
et al.
, Ô¨ÅRidge-based
vessel segmentation in color images of the retina,Ô¨Ç
Medical Imaging, IEEE Transactions on
, vol. 23,
no. 4, pp. 501≈í509, 2004. [Online]. Available:
http://www
:
isi
:
uu
:
nl/Research/Databases/DRIVE/
[SCZ08]
F. Schroff, A. Criminisi, and A. Zisserman,
Ô¨ÅObject class segmentation using random
forests.Ô¨Ç in
BMVC
, 2008, pp. 1≈í10. [On-
line]. Available: http://research
:
microsoft
:
com/pubs/
72423/Criminisi_bmvc2008
:
pdf
[SJC08]
J. Shotton, M. Johnson, and R. Cipolla,
Ô¨ÅSemantic texton forests for image categorization
and segmentation,Ô¨Ç in
Computer vision and
pattern recognition, 2008. CVPR 2008. IEEE
Conference on
. IEEE, Jun. 2008, pp. 1≈í8.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=4587503
[SM11]
C. Sutton and A. McCallum, Ô¨ÅAn introduction
to conditional random elds,Ô¨Ç
Machine Learning
,
vol. 4, no. 4, pp. 267≈í373, 2011. [Online].
Available: http://homepages
:
inf
:
ed
:
ac
:
uk/csutton/
publications/crftutv2
:
pdf
[Smi02]
L. I. Smith, Ô¨ÅA tutorial on principal components
analysis,Ô¨Ç
Cornell University, USA
, vol. 51, p. 52,
2002.
[Smi04]
B. T. Smith, Ô¨ÅLagrange multipliers tutorial in the
context of support vector machines,Ô¨Ç
Memorial Uni-
versity of Newfoundland St. John's, Newfoundland,
Canada
, Jun. 2004.
[SSA12]
D. Schiebener, J. Schill, and T. Asfour, Ô¨ÅDiscovery,
segmentation and reactive grasping of unknown
objects.Ô¨Ç in
Humanoids
, 2012, pp. 71≈í77. [On-
line]. Available: http://h2t
:
anthropomatik
:
kit
:
edu/
pdf/Schiebener2012
:
pdf
[SUM
+
11]
D. Schiebener, A. Ude, J. Morimotot,
T. Asfour, and R. Dillmann, Ô¨ÅSegmentation
and learning of unknown objects through physical
interaction,Ô¨Ç in
Humanoid Robots (Humanoids),
2011 11th IEEE-RAS International Conference
on
. IEEE, 2011, pp. 500≈í506. [Online].
Available: http://ieeexplore
:
ieee
:
org/ielx5/6086637/
6100798/06100843
:
pdf
[SWRC06]
J. Shotton, J. Winn, C. Rother, and A. Criminisi,
Ô¨ÅTextonboost: Joint appearance, shape and context
modeling for multi-class object recognition and
segmentation,Ô¨Ç in
Computer Vision≈íECCV 2006
.
Springer, 2006, pp. 1≈í15. [Online]. Available: http:
//link
:
springer
:
com/chapter/10
:
1007/11744023_1
[TNL14]
J. Tighe, M. Niethammer, and S. Lazebnik,
Ô¨ÅScene parsing with object instances and
occlusion ordering,Ô¨Ç in
Computer Vision and
15
Pattern Recognition (CVPR), 2014 IEEE
Conference on
. IEEE, 2014, pp. 3748≈í3755.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=6909874
[UPH05]
R. Unnikrishnan, C. Pantofaru, and M. Hebert,
Ô¨ÅA measure for objective evaluation of
image segmentation algorithms,Ô¨Ç in
Computer
Vision and Pattern Recognition-Workshops, 2005.
CVPR Workshops. IEEE Computer Society
Conference on
. IEEE, 2005, pp. 34≈í34.
[Online]. Available: http://repository
:
cmu
:
edu/cgi/
viewcontent
:
cgi?article=1365&context=robotics
[vdMPvdH09]
L. J. van der Maaten, E. O. Postma, and H. J.
van den Herik, Ô¨ÅDimensionality reduction: A com-
parative review,Ô¨Ç
Journal of Machine Learning
Research
, vol. 10, no. 1-41, pp. 66≈í71, 2009.
[VOC10]
Ô¨ÅVoc2010 preliminary results,Ô¨Ç 2010. [Online].
Available: http://host
:
robots
:
ox
:
ac
:
uk/pascal/VOC/
voc2010/results/index
:
html
[WAH97]
G.-Q. Wei, K. Arbter, and G. Hirzinger, Ô¨ÅAutomatic
tracking of laparoscopic instruments by color
coding,Ô¨Ç in
CVRMed-MRCAS'97
, ser. Lecture
Notes in Computer Science, J. Troccaz, E. Grimson,
and R. M√∂sges, Eds. Springer Berlin Heidelberg,
1997, vol. 1205, pp. 357≈í366. [Online]. Available:
http://dx
:
doi
:
org/10
:
1007/BFb0029257
[YBCK10]
Z. Yin, R. Bise, M. Chen, and T. Kanade, Ô¨ÅCell
segmentation in microscopy imagery using a
bag of local bayesian classiers,Ô¨Ç in
Biomedical
Imaging: From Nano to Macro, 2010 IEEE
International Symposium on
, Apr. 2010, pp. 125≈í
128. [Online]. Available: http://ieeexplore
:
ieee
:
org/
xpls/abs_all
:
jsp?arnumber=5490399
[YHRF12]
Y. Yang, S. Hallman, D. Ramanan, and
C. C. Fowlkes, Ô¨ÅLayered object models for
image segmentation,Ô¨Ç
Pattern Analysis and
Machine Intelligence, IEEE Transactions on
,
vol. 34, no. 9, pp. 1731≈í1743, Sep. 2012.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=6042883
[ZBS01]
 Y. Zhang, M. Brady, and S. Smith, Ô¨ÅSegmentation
of brain MR images through a hidden Markov
random eld model and the expectation-
maximization algorithm,Ô¨Ç
Medical Imaging, IEEE
Transactions on
, vol. 20, no. 1, pp. 45≈í57, 2001.
[Online]. Available: http://ieeexplore
:
ieee
:
org/xpls/
abs_all
:
jsp?arnumber=906424
[ZGWX05]
S.-C. Zhu, C.-E. Guo, Y. Wang, and Z. Xu, Ô¨ÅWhat
are textons?Ô¨Ç
International Journal of Computer
Vision
, vol. 62, no. 1-2, pp. 121≈í143, 2005.
[Zha12]
Z. Zhang, Ô¨ÅMicrosoft kinect sensor and its effect,Ô¨Ç
MultiMedia, IEEE
, vol. 19, no. 2, pp. 4≈í10, Feb.
2012.
[ZJRP
+
15]
S. Zheng, S. Jayasumana, B. Romera-Paredes,
V. Vineet, Z. Su, D. Du, C. Huang, and
P. H. Torr, Ô¨ÅConditional random elds as
recurrent neural networks,Ô¨Ç in
Proceedings
of the IEEE International Conference on
Computer Vision
, 2015, pp. 1529≈í1537. [Online].
Available: http://www
:
robots
:
ox
:
ac
:
uk/~szheng/
papers/CRFasRNN
:
pdf
G
LOSSARY
ACM
active contour model. 6
BOV
bag-of-visual-words. 5
CNN
Convolution Neuronal Network. 5, 9
CRF
Conditional Random Field. 4, 8, 9, 11
GPU
graphics processing unit. 3
HOG
histogram of oriented gradients. 5, 6, 8
ILSVRC
ImageNet Large-Scale Visual Recognition
Challenge. 9
MAP
Maximum A Posteriori. 8
MR
magnetic resonance. 2, 6
MRF
Markov Random Field. 4, 8
PCA
principal component analysis. 5
RBF
radial basis function. 8
SIFT
scale-invariant feature transform. 5
SVM
Support Vector Machine. 4, 6≈í8
16
A
PPENDIX
A
T
ABLES
Database Image Resolution (width

height)
Number
of
Images
Number
of
Classes
Channels Data source
Colon Crypt DB
(302
px

1116
px
)

(349
px

875
px
) 389
2 3 [CRSS]
DIARETDB1
1500
px

1500
px
89
4 3 [KKV
+
14]
KITTI Road
(1226
px

1242
px
)

(370
px

376
px
) 289
2 3 [FKG13]
MSRCv1
(213
px

320
px
)

(213
px

320
px
) 240
9 3 [MSR]
MSRCv2
(213
px

320
px
)

(162
px

320
px
) 591
23 3 [MSR]
Open-CAS Endoscopic Datasets
640
px

480
px
120
2 3 [MHMK
+
14]
PASCAL VOC 2012
(142
px

500
px
)

( 71
px

500
px
) 2913
20 3 [EVGW
+
12]
Warwick-QU
(567
px

775
px
)

(430
px

522
px
) 165
5 3 [CSM09]
Table I: An overview over publicly available image databases with a semantic segmentation ground trouth.
